{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "2kGKqMJeeqg2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "####\n",
        "#PLEASE READ:\n",
        "#1.)Each problem is marked with a comment header.\n",
        "#2.)Each problem should be run in order.\n",
        "#3.)I have tried to keep variables seperate but running a problem out of order or re-running after having run other problems may lead to issues.\n",
        "#4.)Thank you for grading my work.\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SeDXC1BOXCUU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "4057ff5c-67b9-4a0e-bb59-b1c35e1567c0"
      },
      "cell_type": "code",
      "source": [
        "#Importing dependancies \n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "#Load Data\n",
        "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
        "learningRate = .01"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "je_Hyw91deCH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Defining general functions.\n",
        "def sigmoid(x):\n",
        "  return 1. / (1. + np.exp(-x))\n",
        "\n",
        "def sigmoidDerivative(x):\n",
        "  sig=sigmoid(x)\n",
        "  return sig*(1. - sig)\n",
        "\n",
        "def changeToBinary(label,num):\n",
        "  labelCopy = np.array(label)\n",
        "  for i in range(label.size):\n",
        "    if(labelCopy[i] == num):\n",
        "      labelCopy[i]=1\n",
        "    else:\n",
        "      labelCopy[i]=0 \n",
        "  return labelCopy  \n",
        "\n",
        "def softmax(x):\n",
        "   return np.exp(x) / np.sum(np.exp(x), axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UBylarWLlsyK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###########\n",
        "#PROBLEM 1#\n",
        "###########\n",
        "\n",
        "def miniBatchSGDMeanSquared(x_train,y_train,epoch=10,batch=5,model=0):\n",
        "  np.random.seed(20)\n",
        "  \n",
        "  numFeatures = int(x_train.size/784)\n",
        "  #Flaten to a 2D array\n",
        "  xFlat = (x_train.reshape(60000,784))\n",
        "  yTrain = (y_train.reshape(60000,1))\n",
        "  \n",
        "  #normalize and add bias to features\n",
        "  normFeatures = xFlat/255\n",
        "  featuresBias = np.c_[np.ones((60000,1)),normFeatures]\n",
        "  \n",
        "  weights = np.random.randn(785,1)#785 pixels per image(28^2) +1 for bias\n",
        "  weightsList = []\n",
        "  \n",
        "  #change labels to binary\n",
        "  binaryLabels = changeToBinary(yTrain,model)\n",
        "\n",
        "  for epoch in range(epoch):\n",
        "    #Taken from Linear Regression class notebook by Paul Wocjan\n",
        "    shuffledIndices = np.random.permutation(numFeatures)\n",
        "    shuffledFeatures = featuresBias[shuffledIndices]\n",
        "    shuffledLabels = binaryLabels[shuffledIndices]\n",
        "    \n",
        "    for i in range(0,numFeatures,batch):\n",
        "      #Fetch random sample\n",
        "      randomFeatures = shuffledFeatures[i:i+batch]\n",
        "      randomLabels = shuffledLabels[i:i+batch]\n",
        "      predictions = randomFeatures.dot(weights)\n",
        "      gradient = randomFeatures.T.dot((sigmoid(predictions) - randomLabels) * sigmoidDerivative(predictions))\n",
        "      weights = weights - (learningRate * gradient) \n",
        "    weightsList.append(weights)\n",
        "  return weightsList\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tB6xa4GhIfTy",
        "colab_type": "code",
        "outputId": "50fc1d35-e8a1-44be-f0eb-086703fa4032",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Creating 10 binary models\n",
        "from IPython.display import clear_output\n",
        "digitModels = []\n",
        "#Takes last model -- Could be improved to search for the best model\n",
        "for digit in np.arange(10):\n",
        "  clear_output()\n",
        "  print(digit*10,\"% Done\")\n",
        "  epochWeights = miniBatchSGDMeanSquared(x_train,y_train,epoch =300 , batch = 1000, model=digit)\n",
        "  digitModels.append(epochWeights[-1])\n",
        "clear_output()\n",
        "print('Done')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s0xsx734eC75",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Formatting feature data\n",
        "modelsMSE = np.array(digitModels)\n",
        "normXTestFlat = x_test.reshape(10000,784)/255\n",
        "normXTestFlatBiased = np.c_[np.ones((10000,1)),normXTestFlat]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FVuDE4J4muYT",
        "colab_type": "code",
        "outputId": "6a4c41a3-1685-4a53-addc-8a1af0e3f55d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Testing 10 binary models\n",
        "counterMSE = 0\n",
        "correctMSE = 0\n",
        "\n",
        "for y in y_test:\n",
        "  predictionMSE = []\n",
        "  for i in np.arange(10):\n",
        "    predictionMSE.append(sigmoid(normXTestFlatBiased[counterMSE].dot(modelsMSE[i])))\n",
        "  predictionCE = np.argmax(predictionMSE)\n",
        "  if(predictionCE == y):\n",
        "    correctMSE += 1\n",
        "  counterMSE += 1\n",
        "\n",
        "print(correctMSE/10000,'% Accuracy')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.752 % Accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JV8bekD9792S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###########\n",
        "#PROBLEM 2#\n",
        "###########\n",
        "\n",
        "def miniBatchSGDCrossEntropy(x_train,y_train,epoch=10,batch=5,model=0):\n",
        "  np.random.seed(20)\n",
        "  \n",
        "  numFeatures = int(x_train.size/784)\n",
        "  #Flaten to a 2D array\n",
        "  xFlat = (x_train.reshape(60000,784))\n",
        "  yTrain = (y_train.reshape(60000,1))\n",
        "  \n",
        "  #normalize and add bias to features\n",
        "  normFeatures = xFlat/255\n",
        "  featuresBias = np.c_[np.ones((60000,1)),normFeatures]\n",
        "  \n",
        "  weights = np.random.randn(785,1)#785 pixels per image(28^2) +1 for bias\n",
        "  weightsList = []\n",
        "  \n",
        "  #change labels to binary\n",
        "  binaryLabels = changeToBinary(yTrain,model)\n",
        "\n",
        "  for epoch in range(epoch):\n",
        "    #Taken from Linear Regression class notebook by Paul Wocjan\n",
        "    shuffledIndices = np.random.permutation(numFeatures)\n",
        "    shuffledFeatures = featuresBias[shuffledIndices]\n",
        "    shuffledLabels = binaryLabels[shuffledIndices]\n",
        "    \n",
        "    for i in range(0,numFeatures,batch):\n",
        "      #Fetch random sample\n",
        "      randomFeatures = shuffledFeatures[i:i+batch]\n",
        "      randomLabels = shuffledLabels[i:i+batch]\n",
        "      predictions = randomFeatures.dot(weights)\n",
        "      gradient = randomFeatures.T.dot((sigmoid(predictions) - randomLabels))\n",
        "      weights = weights - (learningRate * gradient) \n",
        "    weightsList.append(weights)\n",
        "  return weightsList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yAyT5xLKib7Z",
        "colab_type": "code",
        "outputId": "17844c16-4564-4a35-df96-3062caed7380",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Creating 10 binary models\n",
        "digitModelsCE = []\n",
        "#Takes last model -- Could be improved to search for the best model\n",
        "for digit in np.arange(10):\n",
        "  clear_output()\n",
        "  print(digit*10,\"% Done\")\n",
        "  epochWeights = miniBatchSGDCrossEntropy(x_train,y_train,epoch =300 , batch = 1000, model=digit)\n",
        "  digitModelsCE.append(epochWeights[-1])\n",
        "clear_output()\n",
        "print('Done')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oFe2D1C8lW0K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Formatting feature data\n",
        "modelsCE = np.array(digitModelsCE)\n",
        "normXTestFlat = x_test.reshape(10000,784)/255\n",
        "normXTestFlatBiased = np.c_[np.ones((10000,1)),normXTestFlat]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzioYSLze7so",
        "colab_type": "code",
        "outputId": "89aa6a1e-5a8d-409e-b8f9-b515bd7ce482",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Testing 10 binary models\n",
        "counterCE = 0\n",
        "correctCE = 0\n",
        "\n",
        "for y in y_test:\n",
        "  predictionCE = []\n",
        "  for i in np.arange(10):\n",
        "    predictionCE.append(sigmoid(normXTestFlatBiased[counterCE].dot(modelsCE[i])))\n",
        "  predictionCE = np.argmax(predictionCE)\n",
        "  if(predictionCE == y):\n",
        "    correctCE += 1\n",
        "  counterCE += 1\n",
        "\n",
        "print(correctCE/10000,'% Accuracy')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8835 % Accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LsLWdI9Whi46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###########\n",
        "#PROBLEM 3#\n",
        "###########\n",
        "\n",
        "#Vectorizes labels \n",
        "def scalarToVector(labels):\n",
        "  vectorizedLabels = []\n",
        "  for scalar in labels:\n",
        "    vector = np.zeros((10,1))\n",
        "    vector[scalar]=1\n",
        "    vectorizedLabels.append(vector)\n",
        "  return np.array(vectorizedLabels).reshape((len(labels),10))    \n",
        "                         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SBInISy1Zkq6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classifier(x_train, y_train, epoch = 50, batch = 50):\n",
        "  np.random.seed(20)\n",
        "  \n",
        "  numFeatures = int(x_train.size/784)\n",
        "  \n",
        "  #Flaten to a 2D array\n",
        "  xFlat = (x_train.reshape(60000,784))\n",
        "  \n",
        "  #Vectorize the lables\n",
        "  yTrain = scalarToVector(y_train)\n",
        "  \n",
        "  #normalize and add bias to features\n",
        "  normFeatures = xFlat/255\n",
        "  featuresBias = np.c_[np.ones((60000,1)),normFeatures]\n",
        "  weights = np.random.randn(785,10)#785 pixels per image(28^2) +1 for bias\n",
        "  weightsList = []\n",
        "\n",
        "  for epoch in range(epoch):\n",
        "    #Taken from Linear Regression class notebook by Paul Wocjan\n",
        "    shuffledIndices = np.random.permutation(numFeatures)\n",
        "    shuffledFeatures = featuresBias[shuffledIndices]\n",
        "    shuffledLabels = yTrain[shuffledIndices]\n",
        "    \n",
        "    for i in range(0,numFeatures,batch):\n",
        "      #Fetch random sample\n",
        "      randomFeatures = shuffledFeatures[i:i+batch]\n",
        "      randomLabels = shuffledLabels[i:i+batch]\n",
        "      predictions = randomFeatures.dot(weights)\n",
        "      gradient = randomFeatures.T.dot((sigmoid(predictions) - randomLabels))\n",
        "      weights = weights - (learningRate * gradient) \n",
        "    weightsList.append(weights)\n",
        "  return weightsList"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azqdqLmxkudW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Train classifier\n",
        "classifierWeights = classifier(x_train,y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qvdV3b2p3YFH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Flattening Features\n",
        "normXTestFlat = x_test.reshape(10000,784)/255\n",
        "normXTestFlatBiased = np.c_[np.ones((10000,1)),normXTestFlat]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "upWlOnSP-bSs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Test Accuracy of classifier\n",
        "percentageList = []\n",
        "max = 0\n",
        "for weights in classifierWeights:\n",
        "  classifierCorrect = 0\n",
        "  for i in np.arange(10000):\n",
        "    prediction = normXTestFlatBiased[i].dot(weights)\n",
        "    if(np.argmax(softmax(prediction)) == y_test[i]):\n",
        "       classifierCorrect += 1\n",
        "  percent = classifierCorrect/10000\n",
        "  percentageList.append(percent)\n",
        "  if(percent > max): max = percent\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pBiyIWdu8htp",
        "colab_type": "code",
        "outputId": "f18009d4-c859-4035-d104-88ff34f59665",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "#charting percentages\n",
        "print('Max Percentage: ',max)\n",
        "print('Final Percentage: ',percentageList[-1])\n",
        "plt.bar(np.arange(len(classifierWeights)),percentageList)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Percentage')\n",
        "plt.title('Classifier')\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max Percentage:  0.9191\n",
            "Final Percentage:  0.9167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe8AAAFnCAYAAACPasF4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "9eM0a8X1_Ale",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "580bc947-513a-4d61-cd09-8b15418d5ae3"
      },
      "cell_type": "code",
      "source": [
        "###########\n",
        "#PROBLEM 4#\n",
        "###########\n",
        "\n",
        "#Importing Keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "#Creating Model\n",
        "kerasClassifier = Sequential()\n",
        "kerasClassifier.add(Dense(units = 784,activation = 'sigmoid', input_shape = (784,)))\n",
        "kerasClassifier.add(Dense(units = 10,activation = 'softmax'))\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "n1TYi4R0LV1z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Specifying parameters for the model\n",
        "kerasClassifier.compile(loss=\"categorical_crossentropy\",\n",
        "                       optimizer=\"sgd\",\n",
        "                       metrics =['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSL3sNcMLX_x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Shaping data\n",
        "xTrain = x_train.reshape(60000,784)\n",
        "yTrain = scalarToVector(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SJIe7mSxYJS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3627
        },
        "outputId": "29e4ab17-a746-400d-d123-c15a0c3fc22a"
      },
      "cell_type": "code",
      "source": [
        "#Fitting model to data\n",
        "kerasClassifier.fit(xTrain,yTrain,epochs=100,batch_size=1000)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 4s 63us/step - loss: 1.4169 - acc: 0.5974\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.7527 - acc: 0.8266\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.5801 - acc: 0.8631\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.4956 - acc: 0.8805\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.4435 - acc: 0.8922\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.4071 - acc: 0.8999\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.3798 - acc: 0.9058\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.3582 - acc: 0.9110\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.3405 - acc: 0.9154\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.3256 - acc: 0.9186\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.3128 - acc: 0.9216\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.3016 - acc: 0.9241\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.2916 - acc: 0.9267\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.2827 - acc: 0.9286\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.2747 - acc: 0.9307\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.2673 - acc: 0.9321\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.2606 - acc: 0.9340\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.2545 - acc: 0.9356\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.2487 - acc: 0.9366\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.2434 - acc: 0.9384\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.2383 - acc: 0.9398\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.2336 - acc: 0.9409\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2292 - acc: 0.9419\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.2250 - acc: 0.9430\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.2210 - acc: 0.9439\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.2172 - acc: 0.9451\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2136 - acc: 0.9463\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.2102 - acc: 0.9470\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2069 - acc: 0.9485\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.2038 - acc: 0.9491\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.2008 - acc: 0.9497\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.1979 - acc: 0.9504\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.1951 - acc: 0.9514\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1924 - acc: 0.9526\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1898 - acc: 0.9531\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1874 - acc: 0.9537\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1850 - acc: 0.9546\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1828 - acc: 0.9549\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1805 - acc: 0.9556\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1783 - acc: 0.9564\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.1762 - acc: 0.9567\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1742 - acc: 0.9571\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1721 - acc: 0.9575\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1702 - acc: 0.9583\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.1684 - acc: 0.9589\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1666 - acc: 0.9593\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1648 - acc: 0.9597\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 3s 43us/step - loss: 0.1630 - acc: 0.9600\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1614 - acc: 0.9605\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.1598 - acc: 0.9612\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.1582 - acc: 0.9615\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1567 - acc: 0.9619\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1552 - acc: 0.9626\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1537 - acc: 0.9629\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1523 - acc: 0.9635\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1509 - acc: 0.9636\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1495 - acc: 0.9640\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1482 - acc: 0.9644\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1469 - acc: 0.9649\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1456 - acc: 0.9651\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1443 - acc: 0.9654\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1431 - acc: 0.9659\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.1418 - acc: 0.9664\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1406 - acc: 0.9664\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1395 - acc: 0.9668\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1384 - acc: 0.9671\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1373 - acc: 0.9676\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1361 - acc: 0.9680\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1351 - acc: 0.9684\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1340 - acc: 0.9688\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1330 - acc: 0.9690\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.1320 - acc: 0.9695\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1310 - acc: 0.9697\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1300 - acc: 0.9700\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1291 - acc: 0.9703\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.1281 - acc: 0.9706\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1272 - acc: 0.9707\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1263 - acc: 0.9711\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1254 - acc: 0.9714\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1245 - acc: 0.9718\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1237 - acc: 0.9719\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1228 - acc: 0.9721\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.1220 - acc: 0.9725\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1211 - acc: 0.9729\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1203 - acc: 0.9730\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 2s 42us/step - loss: 0.1195 - acc: 0.9732\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1187 - acc: 0.9734\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1180 - acc: 0.9738\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1172 - acc: 0.9740\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1165 - acc: 0.9741\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1157 - acc: 0.9743\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1150 - acc: 0.9745\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 2s 41us/step - loss: 0.1142 - acc: 0.9745\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1135 - acc: 0.9748\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.1128 - acc: 0.9749\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1121 - acc: 0.9752\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 54us/step - loss: 0.1114 - acc: 0.9754\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.1107 - acc: 0.9756\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1101 - acc: 0.9758\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 3s 42us/step - loss: 0.1094 - acc: 0.9760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1af457ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "50iE09jWY2-5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Shaping test data\n",
        "xTest = x_test.reshape(10000,784)\n",
        "yTest = scalarToVector(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ELTM_MBuYUMG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c4482186-b8c3-4340-e8e4-81c91d7628e6"
      },
      "cell_type": "code",
      "source": [
        "#Evaluating classifier\n",
        "loss,acc = kerasClassifier.evaluate(xTest,yTest)\n",
        "print(acc*100,'% Accuracy')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 55us/step\n",
            "94.0 % Accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "t_L5MS70O_ui",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "###########\n",
        "#PROBLEM 5#\n",
        "###########\n",
        "\n",
        "#Divides pixels into black or white\n",
        "def blackOrWhite(pixel):\n",
        "  if(pixel>127):\n",
        "    newPixel = 1\n",
        "  else:\n",
        "    newPixel = 0 \n",
        "  return newPixel\n",
        "\n",
        "#Finds the next white pixel\n",
        "def findWhitePixel(image):\n",
        "  rowCount,colCount = image.shape\n",
        "  rowCount = np.arange(rowCount)\n",
        "  colCount = np.arange(colCount)\n",
        "  for i in rowCount:\n",
        "    for j in colCount:\n",
        "      if(image[i][j] == 0):return (i,j)\n",
        "  return (-1,-1)\n",
        "\n",
        "#checks the bounds on an image\n",
        "def boundCheck(x,y,size):\n",
        "  if(x<0 or x>=size):\n",
        "    return False\n",
        "  if(y<0 or y>=size):\n",
        "    return False\n",
        "  return True\n",
        "\n",
        "#does the recursive floodfill\n",
        "def helper(image,x,y):\n",
        "  size=28\n",
        "  image[x][y] = 1\n",
        "  if(boundCheck(x+1,y,size) and image[x+1][y]==0):\n",
        "    image = helper(image,x+1,y)\n",
        "  if(boundCheck(x,y+1,size) and image[x][y+1]==0):\n",
        "    image = helper(image,x,y+1)\n",
        "  if(boundCheck(x-1,y,size) and image[x-1][y]==0):\n",
        "    image = helper(image,x-1,y)\n",
        "  if(boundCheck(x,y-1,size) and image[x][y-1]==0):\n",
        "    image = helper(image,x,y-1)\n",
        "  return image\n",
        "\n",
        "#main body of floodfill\n",
        "def floodFill(image):\n",
        "  x,y = findWhitePixel(image)\n",
        "  if(x==-1):\n",
        "    return 0\n",
        "  else:\n",
        "    image = helper(image,x,y)\n",
        "    return 1 + floodFill(image)\n",
        "\n",
        "#Gets number of white areas in set of images for each image\n",
        "def numberOfWhiteAreas(images):\n",
        "  numWhiteSpaces = []\n",
        "  numImages = int(images.size/784)\n",
        "  for i in np.arange(numImages):\n",
        "    if(i%1000 == 0):\n",
        "      clear_output()\n",
        "      print(i/numImages*100,'% Done')\n",
        "    numWhiteSpaces.append(floodFill(images[i]))\n",
        "  clear_output()\n",
        "  print('Done')  \n",
        "  return np.array(numWhiteSpaces)\n",
        "\n",
        "#Checks averages of rows to see if there is a pixel\n",
        "def getDimensions(image):\n",
        "  tImage = image.T\n",
        "  iMin = -1\n",
        "  tMin = -1\n",
        "  iMax = -1\n",
        "  tMax = -1\n",
        "  for i in np.arange(28):\n",
        "    #Check for height\n",
        "    if(iMin==-1):\n",
        "      if(np.mean(image[i])!=0):\n",
        "        iMin=i\n",
        "    elif(iMax==-1):\n",
        "      if(np.mean(image[i])==0):\n",
        "        iMax=i\n",
        "    #Check for width\n",
        "    if(tMin==-1):\n",
        "      if(np.mean(tImage[i])!=0):\n",
        "        tMin=i\n",
        "    elif(tMax==-1):\n",
        "      if(np.mean(tImage[i])==0):\n",
        "        tMax=i\n",
        "  return (iMax-iMin,tMax-tMin)  \n",
        "\n",
        "#Gets height and width for an image\n",
        "def dimensionsOfDigit(images):\n",
        "  widths = []\n",
        "  heights = []\n",
        "  numImages = int(images.size/784)\n",
        "  for i in np.arange(numImages):\n",
        "    if(i%1000 == 0):\n",
        "      clear_output()\n",
        "      print(i/numImages*100,'% Done')\n",
        "    height,width = getDimensions(images[i])\n",
        "    heights.append(height)\n",
        "    widths.append(width)\n",
        "  clear_output()\n",
        "  print(\"Done\")\n",
        "  return np.array(heights),np.array(widths)\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "44op1Y2uc0Ao",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Creating Black and White Images\n",
        "vectorBW = np.vectorize(blackOrWhite)\n",
        "bWImages = vectorBW(x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f_DTaJkXy2e7",
        "colab_type": "code",
        "outputId": "7d11f44d-9ec3-4aee-ccdc-e7595b2f4cdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Finding number of white areas in each image\n",
        "tempImages = np.copy(bWImages)\n",
        "areasTrain = numberOfWhiteAreas(tempImages)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q_yQWLKGYTkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44c29758-6c69-4341-9b3b-01fa1ef615c1"
      },
      "cell_type": "code",
      "source": [
        "#Finding height and width of Images\n",
        "tempImages = np.copy(bWImages)\n",
        "height,width = dimensionsOfDigit(tempImages)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AEk0Q8XT4Lsp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Reshaping\n",
        "areasTrain = areasTrain.reshape(60000,1)\n",
        "xTrain = x_train.reshape(60000,784)\n",
        "yTrain = scalarToVector(y_train)\n",
        "#Normalizing \n",
        "areasTrainNorm = areasTrain/3\n",
        "height = height/28\n",
        "width = width/28\n",
        "#Concatinating data for classifier\n",
        "xTrainWithAreas = np.c_[height,width,areasTrainNorm,xTrain]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g06x3rXn8qa8",
        "colab_type": "code",
        "outputId": "2a118b1d-de3c-4b53-bf92-005bb04d23cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3555
        }
      },
      "cell_type": "code",
      "source": [
        "# Recreating the Classifier with areas,height and width\n",
        "kerasClassifierWithAreas = Sequential()\n",
        "\n",
        "kerasClassifierWithAreas.add(Dense(units = 785,activation = 'sigmoid', input_shape = (787,)))\n",
        "kerasClassifierWithAreas.add(Dense(units = 10,activation = 'softmax'))\n",
        "kerasClassifierWithAreas.compile(loss=\"categorical_crossentropy\",\n",
        "                       optimizer=\"sgd\",\n",
        "                       metrics =['accuracy'])\n",
        "\n",
        "kerasClassifierWithAreas.fit(xTrainWithAreas,yTrain,epochs=100,batch_size=1000)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 1.3940 - acc: 0.6141\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.7293 - acc: 0.8348\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.5672 - acc: 0.8674\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.4869 - acc: 0.8827\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.4371 - acc: 0.8934\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.4021 - acc: 0.8995\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.3757 - acc: 0.9055\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.3544 - acc: 0.9104\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.3369 - acc: 0.9140\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.3222 - acc: 0.9178\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.3097 - acc: 0.9212\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2985 - acc: 0.9247\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2885 - acc: 0.9264\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2797 - acc: 0.9284\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.2717 - acc: 0.9308\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.2644 - acc: 0.9323\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.2579 - acc: 0.9340\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.2517 - acc: 0.9353\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.2461 - acc: 0.9370\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 51us/step - loss: 0.2409 - acc: 0.9385\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2359 - acc: 0.9398\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2313 - acc: 0.9409\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2270 - acc: 0.9424\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2229 - acc: 0.9432\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2191 - acc: 0.9445\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.2154 - acc: 0.9455\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.2119 - acc: 0.9462\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.2086 - acc: 0.9469\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.2055 - acc: 0.9476\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 48us/step - loss: 0.2024 - acc: 0.9486\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1995 - acc: 0.9490\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 3s 52us/step - loss: 0.1967 - acc: 0.9500\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1941 - acc: 0.9507\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1915 - acc: 0.9513\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1889 - acc: 0.9520\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 3s 49us/step - loss: 0.1866 - acc: 0.9527\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1842 - acc: 0.9537\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1820 - acc: 0.9545\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1799 - acc: 0.9549\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1778 - acc: 0.9557\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1757 - acc: 0.9561\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1738 - acc: 0.9572\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1719 - acc: 0.9575\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1700 - acc: 0.9581\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1682 - acc: 0.9587\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1665 - acc: 0.9592\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1648 - acc: 0.9596\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1631 - acc: 0.9601\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1615 - acc: 0.9604\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 4s 60us/step - loss: 0.1599 - acc: 0.9612\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 3s 55us/step - loss: 0.1584 - acc: 0.9614\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1568 - acc: 0.9618\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1554 - acc: 0.9625\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1539 - acc: 0.9629\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1525 - acc: 0.9629\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1512 - acc: 0.9636\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1499 - acc: 0.9640\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1485 - acc: 0.9642\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1473 - acc: 0.9647\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1460 - acc: 0.9651\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1448 - acc: 0.9654\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1436 - acc: 0.9657\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1424 - acc: 0.9660\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1412 - acc: 0.9664\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1401 - acc: 0.9668\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1390 - acc: 0.9670\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 4s 59us/step - loss: 0.1379 - acc: 0.9673\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 3s 57us/step - loss: 0.1368 - acc: 0.9676\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1358 - acc: 0.9679\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1348 - acc: 0.9680\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1337 - acc: 0.9687\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1327 - acc: 0.9688\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 3s 47us/step - loss: 0.1318 - acc: 0.9692\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1308 - acc: 0.9695\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1299 - acc: 0.9697\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1290 - acc: 0.9699\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1280 - acc: 0.9703\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1271 - acc: 0.9705\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1262 - acc: 0.9706\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1254 - acc: 0.9710\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1245 - acc: 0.9711\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1237 - acc: 0.9714\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 3s 53us/step - loss: 0.1229 - acc: 0.9718\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1220 - acc: 0.9717\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 4s 58us/step - loss: 0.1212 - acc: 0.9721\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 3s 50us/step - loss: 0.1205 - acc: 0.9722\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1197 - acc: 0.9726\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1189 - acc: 0.9727\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1182 - acc: 0.9730\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 3s 46us/step - loss: 0.1174 - acc: 0.9731\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1167 - acc: 0.9735\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1160 - acc: 0.9735\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1153 - acc: 0.9737\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1146 - acc: 0.9741\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1139 - acc: 0.9742\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1132 - acc: 0.9742\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1125 - acc: 0.9745\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1119 - acc: 0.9748\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1112 - acc: 0.9749\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 3s 45us/step - loss: 0.1106 - acc: 0.9751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa1ae942748>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "k7SmnWdeFNPx",
        "colab_type": "code",
        "outputId": "7b9d7a55-b29f-4007-f846-d9eddc72bddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Find white areas of test images\n",
        "bWTestImages = vectorBW(x_test)\n",
        "tempTestImages = np.copy(bWTestImages)\n",
        "areasTest = numberOfWhiteAreas(tempTestImages)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TGElk21witcf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc71f30a-9ecc-4a84-cf88-618894125b98"
      },
      "cell_type": "code",
      "source": [
        "#Find height and width of test images\n",
        "tempTestImages = np.copy(bWTestImages)\n",
        "height,width = dimensionsOfDigit(tempTestImages)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3mNrLBOdbwS1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#append areas,height,width to test data\n",
        "xTest = x_test.reshape(10000,784)\n",
        "yTest = scalarToVector(y_test)\n",
        "\n",
        "areasTest = areasTest.reshape(10000,1)\n",
        "areasTestNorm = areasTest/3\n",
        "height = height/28\n",
        "width = width/28\n",
        "xTest = x_test.reshape(10000,784)\n",
        "xTestWithAreas = np.c_[height,width,areasTestNorm,xTest]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q8BohY-McNXE",
        "colab_type": "code",
        "outputId": "ebeb7aeb-05d9-4296-d249-4d2e8e616206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "#Evaluating accuracy after adding extra features\n",
        "loss,acc = kerasClassifierWithAreas.evaluate(xTestWithAreas,yTest)\n",
        "print(acc*100,'% Accuracy')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 51us/step\n",
            "94.04 % Accuracy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9_p-35u1i4Ar",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#End"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}